name: Sync Azure DevOps Work Items to Chroma

on:
  # Allow manual trigger only for testing
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  sync-ado:
    runs-on: ubuntu-latest
    env:
      S3_BUCKET: preludetx-strinh
      CHROMA_DIR: ./chroma
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::581351078906:role/GitHubActionsS3Access
          aws-region: us-east-1

      - name: Download Chroma directory from S3
        run: |
          mkdir -p chroma
          aws s3 sync s3://${S3_BUCKET}/chroma ./chroma
          ls -R chroma

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install requests
          pip install beautifulsoup4
      
      - name: Get latest modified date from Chroma
        id: getdate
        run: |
          python get_last_date.py
          FILTERED_DATE=$(cat filtered_date.txt)
          echo "FILTERED_DATE=$FILTERED_DATE" >> $GITHUB_ENV
        env:
          DATE_FILE: filtered_date.txt

      - name: Fetch ADO Work Items using python
        run: |
          python fetch_workitems.py | tee fetch_output.log
          NO_NEW_ITEMS=$(grep -o 'NO_NEW_ITEMS=[0-9]' fetch_output.log | cut -d'=' -f2 || echo 0)
          echo "NO_NEW_ITEMS=$NO_NEW_ITEMS" >> $GITHUB_ENV
        env:
          AZURE_DEVOPS_ORG: ${{ secrets.AZURE_DEVOPS_ORG }}
          AZURE_DEVOPS_PROJECT: ${{ secrets.AZURE_DEVOPS_PROJECT }}
          AZURE_DEVOPS_PAT: ${{ secrets.AZURE_DEVOPS_PAT }}
          FILTERED_DATE: ${{ env.FILTERED_DATE }}
      
      - name: Upload exported raw JSON to records
        if: ${{ env.NO_NEW_ITEMS == '0' }}
        uses: actions/upload-artifact@v4
        with:
          name: workitems-export
          path: workitems_export_*.json
          retention-days: 2
      
      - name: Find exported JSON filename
        if: ${{ env.NO_NEW_ITEMS == '0' }}
        id: findfile
        run: |
          FILE=$(ls workitems_export_*.json | sort | tail -n 1)
          echo "WORKITEMS_FILE=$FILE" >> $GITHUB_ENV
          echo "Raw Worklist File: $FILE"

      - name: Clean and chunk text for embeddings
        if: ${{ env.NO_NEW_ITEMS == '0' }}
        run: |
          python clean_workitems.py
          CLEAN_FILE="${WORKITEMS_FILE%.*}_cleaned.json"
          echo "CLEANED_FILE=$CLEAN_FILE" >> $GITHUB_ENV
          echo "Cleaned file: $CLEAN_FILE"
        env:
          INPUT_FILE: ${{ env.WORKITEMS_FILE }}

      - name: Upload exported cleaned JSON to records
        if: ${{ env.NO_NEW_ITEMS == '0' }}
        uses: actions/upload-artifact@v4
        with:
          name: workitems-export-cleaned
          path: workitems_export_*_cleaned.json
          retention-days: 2

      - name: Start Chroma container and update embeddings
        if: ${{ env.NO_NEW_ITEMS == '0' }}
        run: |
         echo "Launching Python container with Chroma data mounted..."
         docker run --rm \
           -v ${{ github.workspace }}/chroma:/chroma \
           -v ${{ github.workspace }}:/app \
           -w /app \
           -e INPUT_FILE=${{ env.CLEANED_FILE }} \
           -e CHROMA_DIR=${{ env.CHROMA_DIR }} \
           python:3.11-slim \
           bash -c "pip install --no-cache-dir chromadb && python upload_workitems.py"

      - name: Upload updated Chroma directory to S3
        if: ${{ env.NO_NEW_ITEMS == '0' }}
        run: |
          echo "Uploading updated ChromaDB directory back to S3..."
          aws s3 sync ./chroma s3://${S3_BUCKET}/chroma --delete
          echo "✅ Upload complete."

      - name: No new work items detected
        if: ${{ env.NO_NEW_ITEMS == '1' }}
        run: echo "✅ No new or modified work items found since last sync. Skipping Chroma update."
